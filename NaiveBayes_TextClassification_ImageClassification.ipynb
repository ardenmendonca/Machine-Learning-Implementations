{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a94ecf",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm:  Real-World practical Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6f6fc",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1: Text Classification using Naive Bayes\n",
    "\n",
    "**Objective:** Implement Naive Bayes for text classification using the Bag-of-Words model and Term Frequency-Inverse Document Frequency (TF-IDF) to classify movie reviews as positive or negative.\n",
    "\n",
    "**Steps:**\n",
    "1. Load a dataset of movie reviews (or any other text data) and preprocess it using tokenization and vectorization.\n",
    "2. Apply both Bag-of-Words and TF-IDF models.\n",
    "3. Train a Naive Bayes classifier on the training set.\n",
    "4. Evaluate the model on the test set using accuracy, precision, recall, and F1-score.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05027c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Bag-of-Words Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       305\n",
      "           1       1.00      0.99      0.99       291\n",
      "\n",
      "    accuracy                           0.99       596\n",
      "   macro avg       1.00      0.99      0.99       596\n",
      "weighted avg       1.00      0.99      0.99       596\n",
      "\n",
      "Classification Report for TF-IDF Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       305\n",
      "           1       1.00      0.99      0.99       291\n",
      "\n",
      "    accuracy                           0.99       596\n",
      "   macro avg       1.00      0.99      0.99       596\n",
      "weighted avg       0.99      0.99      0.99       596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load dataset (20 Newsgroups dataset for text classification)\n",
    "data = fetch_20newsgroups(subset='all', categories=['rec.autos', 'rec.sport.baseball'], shuffle=True, random_state=42)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Preprocessing: Bag-of-Words\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Naive Bayes Classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "print(\"Classification Report for Bag-of-Words Naive Bayes:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Preprocessing: TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Naive Bayes Classifier\n",
    "nb_classifier_tfidf = MultinomialNB()\n",
    "nb_classifier_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_tfidf = nb_classifier_tfidf.predict(X_test_tfidf)\n",
    "print(\"Classification Report for TF-IDF Naive Bayes:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb153d0",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2: Naive Bayes for Image Classification\n",
    "\n",
    "**Objective:** Implement Naive Bayes for image classification using pixel intensities as features. Apply the algorithm to a simplified image dataset (e.g., MNIST) to classify handwritten digits.\n",
    "\n",
    "**Steps:**\n",
    "1. Load the MNIST dataset and flatten the image data into 1D arrays (pixel intensities as features).\n",
    "2. Train a Naive Bayes classifier on the training data.\n",
    "3. Evaluate the performance of the classifier on the test data using accuracy and confusion matrix.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb767d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Classification Accuracy: 0.550952380952381\n",
      "Confusion Matrix:\n",
      "[[1885    3   12    7    5    5   76    2   39   24]\n",
      " [   2 2249    4    9    1    6   28    1   51   13]\n",
      " [ 252   60  652  131    5    9  560    3  433   28]\n",
      " [ 253  119   18  734    2    7  155   15  621  252]\n",
      " [  93   14   24   10  257   10  240   15  362  911]\n",
      " [ 342   60   12   34    5   71  130    4 1055  202]\n",
      " [  26   36   11    0    2    6 1979    0   25    3]\n",
      " [  16   19    5   28   13    4    3  646   65 1449]\n",
      " [  54  270    8   16    4   11   59    6 1125  439]\n",
      " [  16   20   11    5    5    1    1   25   34 1972]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X_mnist = mnist.data\n",
    "y_mnist = mnist.target\n",
    "\n",
    "# Convert labels to integer type\n",
    "y_mnist = y_mnist.astype(int)\n",
    "\n",
    "# Normalize pixel values to [0,1]\n",
    "X_mnist = X_mnist / 255.0\n",
    "\n",
    "# Train-test split\n",
    "X_train_mnist, X_test_mnist, y_train_mnist, y_test_mnist = train_test_split(X_mnist, y_mnist, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Naive Bayes Classifier for image classification\n",
    "nb_classifier_image = GaussianNB()\n",
    "nb_classifier_image.fit(X_train_mnist, y_train_mnist)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_image = nb_classifier_image.predict(X_test_mnist)\n",
    "accuracy_image = accuracy_score(y_test_mnist, y_pred_image)\n",
    "conf_matrix_image = confusion_matrix(y_test_mnist, y_pred_image)\n",
    "\n",
    "print(f\"Image Classification Accuracy: {accuracy_image}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796e38e",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3: Spam Detection using Naive Bayes\n",
    "\n",
    "**Objective:** Build a Naive Bayes classifier to detect spam emails using email datasets (e.g., SMS Spam Collection). Evaluate the performance of the classifier using precision, recall, and F1-score.\n",
    "\n",
    "**Steps:**\n",
    "1. Load and preprocess the email data (or SMS data).\n",
    "2. Convert the text data into numeric format using TF-IDF.\n",
    "3. Train the Naive Bayes classifier to distinguish between spam and non-spam messages.\n",
    "4. Evaluate the model's performance using standard classification metrics.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa0acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam Detection Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1448\n",
      "           1       0.99      0.80      0.89       224\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.98      0.90      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# URL for the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "\n",
    "# Download and extract the ZIP file\n",
    "response = requests.get(url)\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "    # Extract the specific file 'SMSSpamCollection'\n",
    "    with z.open('SMSSpamCollection') as f:\n",
    "        df = pd.read_csv(f, sep='\\t', header=None, names=['label', 'message'])\n",
    "\n",
    "# Encode labels (spam = 1, ham = 0)\n",
    "df['label'] = df['label'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# Preprocess text data\n",
    "X_spam = df['message']\n",
    "y_spam = df['label']\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "tfidf_vectorizer_spam = TfidfVectorizer(stop_words='english')\n",
    "X_spam_tfidf = tfidf_vectorizer_spam.fit_transform(X_spam)\n",
    "\n",
    "# Train-test split\n",
    "X_train_spam, X_test_spam, y_train_spam, y_test_spam = train_test_split(X_spam_tfidf, y_spam, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Naive Bayes Classifier\n",
    "nb_classifier_spam = MultinomialNB()\n",
    "nb_classifier_spam.fit(X_train_spam, y_train_spam)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_spam = nb_classifier_spam.predict(X_test_spam)\n",
    "print(\"Spam Detection Classification Report:\")\n",
    "print(classification_report(y_test_spam, y_pred_spam))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
