{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4460ea3",
   "metadata": {},
   "source": [
    "# Feature Scaling and SVM\n",
    "\n",
    "## Task\n",
    "Demonstrate the impact of feature scaling on SVM performance with and without kernel transformation.\n",
    "\n",
    "## Objective\n",
    "Highlight the importance of preprocessing steps in SVM implementations.\n",
    "\n",
    "## Implementation\n",
    "Here, we compare the performance of an SVM on scaled versus unscaled data, using both linear and RBF kernels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44bee143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 1.0\n",
      "Accuracy with scaling: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM without scaling\n",
    "svm_noscale = SVC(kernel='linear')\n",
    "svm_noscale.fit(X_train, y_train)\n",
    "accuracy_noscale = accuracy_score(y_test, svm_noscale.predict(X_test))\n",
    "\n",
    "# SVM with scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_scale = SVC(kernel='linear')\n",
    "svm_scale.fit(X_train_scaled, y_train)\n",
    "accuracy_scale = accuracy_score(y_test, svm_scale.predict(X_test_scaled))\n",
    "\n",
    "print(f'Accuracy without scaling: {accuracy_noscale}')\n",
    "print(f'Accuracy with scaling: {accuracy_scale}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699538ec",
   "metadata": {},
   "source": [
    "## SVM with Custom Kernels\n",
    "\n",
    "## Task\n",
    "Implement custom kernels for SVMs and compare their effectiveness on specific types of data structures.\n",
    "\n",
    "## Objective\n",
    "Explore the flexibility of SVMs with kernels tailored to particular problems.\n",
    "\n",
    "## Implementation\n",
    "We implement a simple custom kernel for SVM and compare it to standard kernels on a simple dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee23f028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with custom kernel: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Custom kernel function: polynomial kernel\n",
    "def my_kernel(X, Y):\n",
    "    return (1 + np.dot(X, Y.T)) ** 2\n",
    "\n",
    "svm_custom = SVC(kernel=my_kernel)\n",
    "svm_custom.fit(X_train_scaled, y_train)\n",
    "accuracy_custom = accuracy_score(y_test, svm_custom.predict(X_test_scaled))\n",
    "\n",
    "print(f'Accuracy with custom kernel: {accuracy_custom}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395345d8",
   "metadata": {},
   "source": [
    "## One-Class SVM\n",
    "\n",
    "## Task\n",
    "Use one-class SVM for anomaly detection in datasets.\n",
    "\n",
    "## Objective\n",
    "Understand how SVM can be adapted for unsupervised problems, specifically for identifying outliers.\n",
    "\n",
    "## Implementation\n",
    "We demonstrate the use of a one-class SVM to detect outliers in a dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3fe5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected outliers: 25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Simulate data with outliers\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "X_inliers = np.random.normal(size=(100, 2))\n",
    "X_total = np.vstack((X_inliers, X_outliers))\n",
    "\n",
    "# One-class SVM\n",
    "oc_svm = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "oc_svm.fit(X_inliers)\n",
    "\n",
    "y_pred = oc_svm.predict(X_total)\n",
    "n_error = y_pred[y_pred == -1].size\n",
    "\n",
    "print(f'Number of detected outliers: {n_error}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c812ad9",
   "metadata": {},
   "source": [
    "## Incremental Learning with SVM\n",
    "\n",
    "## Task\n",
    "Implement an online learning algorithm with SVM to handle large datasets that cannot fit into memory.\n",
    "\n",
    "## Objective\n",
    "Learn techniques for training models incrementally, essential for real-time data processing.\n",
    "\n",
    "## Implementation\n",
    "We use the incremental learning capabilities of scikit-learn's SGDClassifier to simulate an SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ae7429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental learning accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Incremental SVM using SGDClassifier\n",
    "svm_incremental = SGDClassifier(loss='hinge')  # 'hinge' loss simulates SVM\n",
    "\n",
    "# Simulating incremental learning\n",
    "for _ in range(5):  # Simulate 5 batches of data\n",
    "    svm_incremental.partial_fit(X_train_scaled[:20], y_train[:20], classes=np.unique(y_train))\n",
    "\n",
    "accuracy_incremental = accuracy_score(y_test, svm_incremental.predict(X_test_scaled))\n",
    "print(f'Incremental learning accuracy: {accuracy_incremental}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce6868",
   "metadata": {},
   "source": [
    "## SVM for Feature Selection\n",
    "\n",
    "## Task\n",
    "Utilize SVMs with recursive feature elimination to identify the most significant features for classification tasks.\n",
    "\n",
    "## Objective\n",
    "Understand the role of feature selection in improving model accuracy and efficiency.\n",
    "\n",
    "## Implementation\n",
    "We demonstrate the use of SVM with recursive feature elimination (RFE) to identify significant features in the Iris dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd4d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Feature selection with SVM and RFE\n",
    "svm_rfe = SVC(kernel=\"linear\")\n",
    "selector = RFE(svm_rfe, n_features_to_select=2, step=1)\n",
    "selector = selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Selected features: {selector.support_}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
